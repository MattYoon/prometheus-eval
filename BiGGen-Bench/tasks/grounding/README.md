10 tasks related to assessing the Grounding capabilities of LLMs.
The community has mostly focused on grounding LLMs with additional context retrieved from other knowledge sources to avoid hallucination. In this work, we employ a wider scope of definition.

We explore the ability to strictly follow or adapt on the content specified in the input such as a system prompt, instruction, additional context, or in-context demonstrations. 

Moreover, we also explore scenarios where there is a conflict between each component (e.g., conflict between the instruction and in-context demonstration). In these scenarios, there is no straight-forward answer. We put first priority on the system prompt, and treat all the other components equally! In other words, in these scenarios, instead of evaluating with a "higher-is-better" standard, we examine how different LLMs react to them. These tasks are marked as **Subjective**.

Name | Description | Data Annotator (Group A) | Data Reviewer (Group A) | Data Annotator (Group B) | Related paper 
---- | ----------- | -------------------- | -------------------- | --------------- | --------------- |
[follow_the_system_prompt](follow_the_system_prompt/) | Tasks that require to follow an unusual and challenging system prompt that requires acting beyond as a "Helpful Assistant". | Jinheon Baek | Chaeeun Kim, Miyoung Ko | ? | [link1](https://arxiv.org/abs/2311.10054), [link2](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/system-message) |
[json_csv_xml](json_csv_xml/) | Tasks that require to process a given complicated data (at least 100 rows) in the requested output format (e.g., nested json format). | Jinheon Baek | Chaeeun Kim, Miyoung Ko | ? | [link1](https://arxiv.org/abs/2310.20111), [link2](https://github.com/1rgs/jsonformer)
[role_playing](role_playing/) | Tasks that require to simulate a role of a certain historical figure or character. | Jinheon Baek | Chaeeun Kim, Miyoung Ko | ? | [link](https://arxiv.org/abs/2310.00746) |
[simulator](simulator/) | Tasks that require the LLM to function as a simulator of the requested target (e.g., user or a terminal system). | Jinheon Baek | Chaeeun Kim, Miyoung Ko | ? | [link1](https://arxiv.org/abs/2306.09821), [link2](https://www.engraved.blog/building-a-virtual-machine-inside/) |
[false_context](false_context/) | This task is **Subjective**. Tasks that require to generate an output when false information is given as additional context. The LLM might either use the knowledge stored in its parametric memory or strictly ground on the given context. | Jinheon Baek | Chaeeun Kim, Miyoung Ko | ? | [link1](https://arxiv.org/abs/2310.00935) [link2](https://arxiv.org/abs/2305.01579) |
[temporal_grounding](temporal_grounding/) | Tasks that require to ground on a given time when additional context is given. | Haebin Shin | Yejin Cho, Hanseok Oh | ? | [link](https://arxiv.org/abs/2311.08398) |
[multi_source](multi_source/) | This task is **Subjective**. Tasks that require to generate based on multiple knowledge sources that might potentially conflict with one another. The LLM might either determine which information is correct or try to summarize the conflicting viewpoints. | Haebin Shin | Yejin Cho, Hanseok Oh | ? | [link](https://arxiv.org/abs/2205.12221) |
[demo_vs_instruction](demo_vs_instruction/) | This task is **Subjective**. Tasks that where the instruction and demonstrations are somehow related but show different patterns. The objective of this task is to check whether the LLM prefers to ground on the demonstrations or the instruction. | Haebin Shin | Yejin Cho, Hanseok Oh | ? | NOT AVAILABLE |
[system_prompt_vs_demo](system_prompt_vs_demo/) | Tasks where the system prompt and demonstrations are somehow related but show different patterns. The objective of this task is to check whether the LLM strictly gorunds on the system prompt. | Haebin Shin | Yejin Cho, Hanseok Oh | ? | NOT AVAILABLE |
[system_prompt_vs_instruction](system_prompt_vs_instruction/) | Tasks where the system prompt and instruction are somehow related but show different patterns. The objective of this task is to check whether the LLM strictly grounds on the system prompt. | Haebin Shin | Yejin Cho, Hanseok Oh | ? | NOT AVAILABLE |